{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f746c19c-aae3-492b-a692-09a6b19bcf92",
   "metadata": {},
   "source": [
    "# TensorBoard Scalars: Logging training metrics in Keras\n",
    "\n",
    "## Overview\n",
    "\n",
    "机器学习总是涉及了解关键指标，如损失以及它们如何随着训练的进展而变化。例如，这些指标可以帮助您了解您是否过拟合，或者您是否进行了不必要的训练。您可能希望在不同的训练运行中比较这些指标，以帮助调试和改进您的模型。\n",
    "\n",
    "TensorBoard的 **Scalars Dashboard** 允许您毫不费力地使用简单的API可视化这些指标。本教程提供了非常基本的示例，以帮助您了解如何在开发 Keras 模型时将这些API与TensorBoard一起使用。您将学习如何使用Keras TensorBoard回调和TensorFlow Summary API来可视化默认和自定义标量。\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e767b11-91d5-4c8e-a7e4-be5a24b175be",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73812d07-3391-495a-aa83-9d923ab92e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version:  2.6.0\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from packaging import version\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "print(\"TensorFlow version: \", tf.__version__)\n",
    "assert version.parse(tf.__version__).release[0] >= 2, \\\n",
    "    \"This notebook requires TensorFlow 2.0 or above.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc5c5dc-2692-4e16-a4a8-55bf73b88a9f",
   "metadata": {},
   "source": [
    "## Set up data for a simple regression\n",
    "\n",
    "您现在将使用Keras来计算回归，即找到配对数据集的最佳拟合线。（虽然使用神经网络和梯度下降对此类问题来说太过分了，但它确实是一个非常容易理解的例子。）\n",
    "\n",
    "您将使用TensorBoard来观察训练和测试 **损失** 在各个 epoch 的变化。希望随着时间的推移，您会看到训练和测试损失减少，然后保持稳定。\n",
    "\n",
    "首先，大致沿着y = 0.5x + 2线生成1000个数据点。将这些数据点拆分为训练和测试集。你的希望是神经网络学会这种关系。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbe05251-9d72-4e8b-a016-a882ee4d5c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_size = 1000\n",
    "# 80% of the data is for training.\n",
    "train_pct = 0.8\n",
    "\n",
    "train_size = int(data_size * train_pct)\n",
    "\n",
    "# Create some input data between -1 and 1 and randomize it.\n",
    "x = np.linspace(-1, 1, data_size)\n",
    "np.random.shuffle(x)\n",
    "\n",
    "# Generate the output data.\n",
    "# y = 0.5x + 2 + noise\n",
    "y = 0.5 * x + 2 + np.random.normal(0, 0.05, (data_size, ))\n",
    "\n",
    "# Split into test and train pairs.\n",
    "x_train, y_train = x[:train_size], y[:train_size]\n",
    "x_test, y_test = x[train_size:], y[train_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e56b26d-23d3-4d96-b7bd-66afdbbca578",
   "metadata": {},
   "source": [
    "## Training the model and logging loss\n",
    "\n",
    "您现在可以定义、训练和评估您的模型了。\n",
    "\n",
    "要在训练时记录损失标量，您需要执行以下操作：\n",
    "\n",
    "- 创建 Keras TensorBoard 回调\n",
    "- 指定日志目录\n",
    "- 将 TensorBoard 回调传递给 Keras 的 Model.fit()。\n",
    "\n",
    "TensorBoard从日志目录层次结构中读取日志数据。在本笔记本中，根日志目录是 `logs/scalars`，后缀为时间戳子目录。时间戳子目录使您可以在使用TensorBoard和迭代模型时轻松识别和选择训练运行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab01c167-3d41-4ce1-ad26-2f26f5fcdd14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-11 18:40:00.546609: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.\n",
      "2022-04-11 18:40:00.546620: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.\n",
      "2022-04-11 18:40:00.546912: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.\n",
      "2022-04-11 18:40:00.550266: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-04-11 18:40:00.550407: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "Training ... With default parameters, this takes less than 10 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-11 18:40:01.187780: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2022-04-11 18:40:01.187964: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-04-11 18:40:01.255673: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-11 18:40:01.651416: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-11 18:40:01.679157: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.\n",
      "2022-04-11 18:40:01.679166: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.\n",
      "2022-04-11 18:40:01.681821: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
      "2022-04-11 18:40:01.685197: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.\n",
      "2022-04-11 18:40:01.690056: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: logs/scalars/20220411-184000/train/plugins/profile/2022_04_11_18_40_01\n",
      "\n",
      "2022-04-11 18:40:01.690992: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to logs/scalars/20220411-184000/train/plugins/profile/2022_04_11_18_40_01/Shawns.local.trace.json.gz\n",
      "2022-04-11 18:40:01.694645: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: logs/scalars/20220411-184000/train/plugins/profile/2022_04_11_18_40_01\n",
      "\n",
      "2022-04-11 18:40:01.694760: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to logs/scalars/20220411-184000/train/plugins/profile/2022_04_11_18_40_01/Shawns.local.memory_profile.json.gz\n",
      "2022-04-11 18:40:01.695300: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: logs/scalars/20220411-184000/train/plugins/profile/2022_04_11_18_40_01\n",
      "Dumped tool data for xplane.pb to logs/scalars/20220411-184000/train/plugins/profile/2022_04_11_18_40_01/Shawns.local.xplane.pb\n",
      "Dumped tool data for overview_page.pb to logs/scalars/20220411-184000/train/plugins/profile/2022_04_11_18_40_01/Shawns.local.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to logs/scalars/20220411-184000/train/plugins/profile/2022_04_11_18_40_01/Shawns.local.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to logs/scalars/20220411-184000/train/plugins/profile/2022_04_11_18_40_01/Shawns.local.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to logs/scalars/20220411-184000/train/plugins/profile/2022_04_11_18_40_01/Shawns.local.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average test loss:  0.044937716908752916\n"
     ]
    }
   ],
   "source": [
    "logdir = \"logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(16, input_dim=1),\n",
    "    keras.layers.Dense(1),\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    loss='mse', # keras.losses.mean_squared_error\n",
    "    optimizer=keras.optimizers.SGD(learning_rate=0.2),\n",
    ")\n",
    "\n",
    "print(\"Training ... With default parameters, this takes less than 10 seconds.\")\n",
    "training_history = model.fit(\n",
    "    x_train, # input\n",
    "    y_train, # output\n",
    "    batch_size=train_size,\n",
    "    verbose=0, # Suppress chatty output; use Tensorboard instead\n",
    "    epochs=100,\n",
    "    validation_data=(x_test, y_test),\n",
    "    callbacks=[tensorboard_callback],\n",
    ")\n",
    "\n",
    "print(\"Average test loss: \", np.average(training_history.history['loss']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b7d43a-765c-44a8-b70f-d2aa8be04838",
   "metadata": {},
   "source": [
    "## Examining loss using TensorBoard\n",
    "\n",
    "现在，启动TensorBoard，指定您上面使用的根日志目录。\n",
    "\n",
    "等待几秒钟，让TensorBoard的用户界面旋转。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "caecf5fb-2aac-4960-9c7d-f43178afcb3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-bb96d67397784fba\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-bb96d67397784fba\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/scalars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd59fad-077a-421b-8675-a10cac43f114",
   "metadata": {},
   "source": [
    "您可能会看到TensorBoard显示消息“No dashboards are active for the current data set”。这是因为初始日志数据尚未保存。随着训练的进行，Keras模型将开始记录数据。TensorBoard将定期刷新并显示您的标量指标。如果您不耐烦，您可以点击右上角的刷新箭头。\n",
    "\n",
    "当您观看训练进度时，请注意训练和验证损失如何迅速减少，然后保持稳定。事实上，你可以在25个 epoch 后停止训练，因为在那之后训练没有太大改善。\n",
    "\n",
    "将鼠标悬停在图表上以查看特定数据点。您还可以尝试使用鼠标放大，或选择其中的一部分以查看更多详细信息。\n",
    "\n",
    "注意左侧的 “Runs” 选择器。“run” 表示一轮训练的一组日志，在这种情况下是 `Model.fit()` 的结果。随着时间的推移，开发人员在实验和开发模型时通常会运行很多很多。\n",
    "\n",
    "使用 Runs 选择器选择特定 runs，或仅从训练或验证中进行选择。比较 runs 将帮助您评估哪个版本的代码可以更好地解决问题。\n",
    "\n",
    "好的，TensorBoard的损失图表明，在训练和验证中，损失持续下降，然后稳定下来。这意味着该模型的指标可能非常好！现在看看模型在现实生活中的表现。\n",
    "\n",
    "给定输入数据（60、25、2），线y = 0.5x + 2应该产生（32, 14.5, 3）。模型是否一致？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4dfd814-5e3c-4ee2-8e81-75c93062f099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[31.797571]\n",
      " [14.415272]\n",
      " [ 2.992618]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-11 18:45:45.627789: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "print(model.predict([60, 25, 2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0cf041-ac76-40d6-9171-3791337ba5c3",
   "metadata": {},
   "source": [
    "## Logging custom scalars\n",
    "\n",
    "如果您想记录自定义值，例如动态学习率，该怎么办？为此，您需要使用TensorFlow Summary API。\n",
    "\n",
    "重新训练回归模型并记录自定义学习率。方法如下：\n",
    "\n",
    "- 使用 `tf.summary.create_file_writer()` 创建一个 file writer。\n",
    "- 定义自定义学习速率函数。这将传递给 Keras `LearningRateScheduler` 回调。\n",
    "- 在学习率函数中，使用 `tf.summary.scalar()` 记录自定义学习率。\n",
    "- 将 `LearningRateScheduler` 回调传递给 `Model.fit()`。\n",
    "\n",
    "一般来说，要记录自定义标量，您需要将 `tf.summary.scalar()` 与 file writer 一起使用。file writer 负责将此运行的数据写入指定目录，并在您使用 `tf.summary.scalar()` 时隐式使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ecdb01a-dded-49f5-8613-ff7a6cddee0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-11 18:53:52.065912: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.\n",
      "2022-04-11 18:53:52.065933: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.\n",
      "2022-04-11 18:53:52.066018: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.\n",
      "2022-04-11 18:53:52.163229: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-11 18:53:52.223709: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-11 18:53:52.247169: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.\n",
      "2022-04-11 18:53:52.247178: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.\n",
      "2022-04-11 18:53:52.256945: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
      "2022-04-11 18:53:52.257222: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.\n",
      "2022-04-11 18:53:52.257713: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: logs/scalars/20220411-185352/train/plugins/profile/2022_04_11_18_53_52\n",
      "\n",
      "2022-04-11 18:53:52.258034: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to logs/scalars/20220411-185352/train/plugins/profile/2022_04_11_18_53_52/Shawns.local.trace.json.gz\n",
      "2022-04-11 18:53:52.258261: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: logs/scalars/20220411-185352/train/plugins/profile/2022_04_11_18_53_52\n",
      "\n",
      "2022-04-11 18:53:52.258364: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to logs/scalars/20220411-185352/train/plugins/profile/2022_04_11_18_53_52/Shawns.local.memory_profile.json.gz\n",
      "2022-04-11 18:53:52.259000: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: logs/scalars/20220411-185352/train/plugins/profile/2022_04_11_18_53_52\n",
      "Dumped tool data for xplane.pb to logs/scalars/20220411-185352/train/plugins/profile/2022_04_11_18_53_52/Shawns.local.xplane.pb\n",
      "Dumped tool data for overview_page.pb to logs/scalars/20220411-185352/train/plugins/profile/2022_04_11_18_53_52/Shawns.local.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to logs/scalars/20220411-185352/train/plugins/profile/2022_04_11_18_53_52/Shawns.local.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to logs/scalars/20220411-185352/train/plugins/profile/2022_04_11_18_53_52/Shawns.local.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to logs/scalars/20220411-185352/train/plugins/profile/2022_04_11_18_53_52/Shawns.local.kernel_stats.pb\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logdir = \"logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "file_writer = tf.summary.create_file_writer(logdir + \"/metrics\")\n",
    "file_writer.set_as_default()\n",
    "\n",
    "def lr_schedule(epoch):\n",
    "    learning_rate = 0.2\n",
    "    if epoch > 10:\n",
    "        learning_rate = 0.02\n",
    "    if epoch > 20:\n",
    "        learning_rate = 0.01\n",
    "    if epoch > 50:\n",
    "        learning_rate = 0.005\n",
    "        \n",
    "    tf.summary.scalar('learning rate', data=learning_rate, step=epoch)\n",
    "    return learning_rate\n",
    "\n",
    "lr_callback = keras.callbacks.LearningRateScheduler(lr_schedule)\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(16, input_dim=1),\n",
    "    keras.layers.Dense(1),\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    loss='mse', # keras.losses.mean_squared_error\n",
    "    optimizer=keras.optimizers.SGD(),\n",
    ")\n",
    "\n",
    "training_history = model.fit(\n",
    "    x_train, # input\n",
    "    y_train, # output\n",
    "    batch_size=train_size,\n",
    "    verbose=0, # Suppress chatty output; use Tensorboard instead\n",
    "    epochs=100,\n",
    "    validation_data=(x_test, y_test),\n",
    "    callbacks=[tensorboard_callback, lr_callback],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d238330-771d-4730-b9d6-babfbcfb9edc",
   "metadata": {},
   "source": [
    "让我们再看看TensorBoard。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "395cc53c-ea4f-4d74-963f-265ae01e5e84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 76241), started 0:13:49 ago. (Use '!kill 76241' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-49903bc5e47da486\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-49903bc5e47da486\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/scalars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e07301-a055-484f-b472-69fd216f24ed",
   "metadata": {},
   "source": [
    "使用左侧的“Runs”选择器，请注意您运行了 `<timestamp>/metrics` 。选择此运行会显示一个“学习率”图表，允许您验证此运行期间学习率的进度。\n",
    "\n",
    "您还可以将此运行的训练和验证损失曲线与之前的运行进行比较。您还可能会注意到，学习率时间表根据 epoch 返回了离散值，但学习率图可能看起来很流畅。TensorBoard有一个平滑参数，您可能需要将该参数调低到零才能看到未平滑的值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83d5c07c-c17a-49df-a21d-a6a866c9741f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[31.797157 ]\n",
      " [14.415102 ]\n",
      " [ 2.9926066]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-11 18:55:53.074869: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "print(model.predict([60, 25, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf038073-bd8b-4f77-8006-28eddb770475",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
