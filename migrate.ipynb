{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55e26572-8fd8-4778-a17e-2f50e4922cde",
   "metadata": {},
   "source": [
    "# Migrating tf.summary usage to TF 2.x\n",
    "\n",
    "> Note: 本文档适用于已经熟悉TensorFlow 1.x TensorBoard并希望将大型TensorFlow代码库从TensorFlow 1.x迁移到2.x的人。如果您是TensorBoard的新手，请参阅入门文档。如果您正在使用tf.keras，您可能不需要采取任何行动来升级到TensorFlow 2.x。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28980a60-a614-4594-9f33-0aa8ac6745c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c370cd-4bbd-4755-82ad-e3af3c3bfb23",
   "metadata": {},
   "source": [
    "TensorFlow 2.x包括对 `tf.summary` API的重大更改，该API用于在 TensorBoard 中编写摘要数据进行可视化。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee5cf3a-06b9-4262-beb7-cb9a3de2df10",
   "metadata": {},
   "source": [
    "# What's changed\n",
    "\n",
    "将 `tf.summary` API视为两个子API是有用的：\n",
    "\n",
    "- 一套用于记录 individual summaries 的操作 - `summary.scalar()`, `summary.histogram()`, `summary.image()`, `summary.audio()` 和 `summary.text()`。\n",
    "- 编写逻辑，收集这些单独的摘要并将其写入特殊格式的日志文件（然后TensorBoard读取该文件以生成可视化）。\n",
    "\n",
    "## In TF1.x\n",
    "\n",
    "这两部分必须手动连接在一起-通过 `Session.run()` 获取摘要操作输出并调用 `FileWriter.add_summary(output，step)`。 `v1.summary.merge_all()` op 通过使用 graph 集合来聚合所有摘要操作输出，但这种方法对于 eager 执行和控制流仍然不起作用，使其特别不适合TF 2.x。\n",
    "\n",
    "## In TF2.X\n",
    "\n",
    "这两部分紧密集成，现在单个 `tf.summary` 操作在执行时会立即写入数据。使用模型代码中的API应该看起来仍然很熟悉，但现在在保持 graph-mode 兼容的同时，eager 执行是友好的。集成两个API意味着 `summary.FileWriter` 现在是 TensorFlow 执行上下文的一部分，可以直接由 `tf.summary` 操作访问，因此 configuring writers 是看起来不同的主要部分。\n",
    "\n",
    "eager 执行的用法示例，TF 2.x中的默认值："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c06ff4df-6ab1-4d9a-b63d-7e07fbb763e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-11 11:03:07.722744: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-04-11 11:03:07.723758: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "writer = tf.summary.create_file_writer(\"/tmp/mylogs/eager\")\n",
    "\n",
    "with writer.as_default():\n",
    "    for step in range(100):\n",
    "        tf.summary.scalar(\"my_metric\", 0.5, step=step)\n",
    "        writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7efb2e11-0f17-45ee-ac54-2c0bb725e782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "events.out.tfevents.1649646187.Shawns.local.37805.0.v2\n"
     ]
    }
   ],
   "source": [
    "ls /tmp/mylogs/eager"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338f0b72-d26c-4c7f-901d-4e18e52d4771",
   "metadata": {},
   "source": [
    "`tf.function` graph 执行的示例用法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef9331d1-9f86-4728-aeed-ef818fba70c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-11 11:05:31.956152: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2022-04-11 11:05:31.958669: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-04-11 11:05:31.959817: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "writer = tf.summary.create_file_writer(\"/tmp/mylogs/tf_function\")\n",
    "\n",
    "@tf.function\n",
    "def my_func(step):\n",
    "    with writer.as_default():\n",
    "        tf.summary.scalar(\"my_metric\", 0.5, step=step)\n",
    "        \n",
    "for step in tf.range(100, dtype=tf.int64):\n",
    "    my_func(step)\n",
    "    writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba7adbc2-3a7b-4b07-aac3-175f60093316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "events.out.tfevents.1649646331.Shawns.local.37805.1.v2\n"
     ]
    }
   ],
   "source": [
    "ls /tmp/mylogs/tf_function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675f7cad-a3ec-43a2-9cd5-b613f7d3f2d2",
   "metadata": {},
   "source": [
    "传统 TF 1.x graph 执行的示例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ee11e8c-0237-481b-a086-f442407ee0e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-11 11:09:41.660502: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-04-11 11:09:41.660527: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2022-04-11 11:09:41.662150: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-11 11:09:41.667329: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-11 11:09:41.670129: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-11 11:09:41.679195: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "g = tf.compat.v1.Graph()\n",
    "with g.as_default():\n",
    "    step = tf.Variable(0, dtype=tf.int64)\n",
    "    step_update = step.assign_add(1)\n",
    "    writer = tf.summary.create_file_writer(\"/tmp/mylogs/session\")\n",
    "    with writer.as_default():\n",
    "        tf.summary.scalar(\"my_metric\", 0.5, step=step)\n",
    "    all_summary_ops = tf.compat.v1.summary.all_v2_summary_ops()\n",
    "    writer_flush = writer.flush()\n",
    "    \n",
    "with tf.compat.v1.Session(graph=g) as sess:\n",
    "    sess.run([writer.init(), step.initializer])\n",
    "    \n",
    "    for i in range(100):\n",
    "        sess.run(all_summary_ops)\n",
    "        sess.run(step_update)\n",
    "        sess.run(writer_flush)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65ff7fcc-06db-4541-9542-8e363e869202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "events.out.tfevents.1649646581.Shawns.local.37805.2.v2\n"
     ]
    }
   ],
   "source": [
    "ls /tmp/mylogs/session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963468ef-3f19-474f-bfbc-eabdb8935d7a",
   "metadata": {},
   "source": [
    "# Converting your code\n",
    "\n",
    "将现有的 `tf.summary` 使用转换为TF 2.x API无法可靠地自动化，因此 `tf_upgrade_v2` 脚本只是将其全部重写为 `tf.compat.v1.summary`，并且不会自动启用 TF 2.x行为。\n",
    "\n",
    "## Partial  Migration\n",
    "\n",
    "为了使仍然严重依赖 TF 1.x summary API 日志操作（如 `tf.compat.v1.summary.scalar()` ）的模型代码用户更容易迁移到TF 2.x，可以首先仅迁移写入API，允许稍后完全迁移模型代码中的单个TF 1.x摘要操作。\n",
    "\n",
    "为了支持这种迁移风格，`tf.compat.v1.summary` 将在以下条件下自动转发到 TF 2.x：\n",
    "\n",
    "- 最外层的上下文是 eager 模式\n",
    "- 设置了默认的TF 2.x summary writer\n",
    "- 为 wruter 设置了 step 的非空值(使用 `tf.summary.SummaryWriter.as_default`, `tf.summary.experimental.set_step` 或者 `tf.compat.v1.train.create_global_step`)\n",
    "\n",
    "\n",
    "请注意，当调用TF 2.x摘要实现时，返回值将是一个空的 bytestring 张量，以避免重复的摘要写入。此外，输入参数 forwarding 是尽最大努力，并非所有参数都将被保留（例如，将支持 `family` 参数，而 `collections` 将被删除）。\n",
    "\n",
    "在 `tf.compat.v1.summary.scalar` 中调用 `tf.summary.scalar` 行为的示例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43a0e020-9abd-4f50-a353-c72130e4fde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.enable_v2_behavior()\n",
    "\n",
    "writer = tf.summary.create_file_writer(\"/tmp/mylogs/enable_v2_in_v1\")\n",
    "with writer.as_default(step=0):\n",
    "    tf.compat.v1.summary.scalar('float', tf.constant(1.0), family=\"family\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4c6bd5-aaf4-46a8-a42a-093493417573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
