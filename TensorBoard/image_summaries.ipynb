{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e532dc0-75d8-4b9c-8cd6-ce7f6801dd70",
   "metadata": {},
   "source": [
    "# Displaying image data in TensorBoard\n",
    "\n",
    "## Overview\n",
    "\n",
    "使用 TensorFlow Image Summary API，您可以轻松记录张量和任意图像，并在 TensorBoard 中查看它们。 这对于采样、检查您的输入数据，或可视化层权重和生成的张量非常有帮助。您还可以将诊断数据记录为图像，这有助于您的模型开发过程。\n",
    "\n",
    "在本教程中，您将学习如何使用 Image Summary API 将张量可视化为图像。您还将学习如何拍摄任意图像，将其转换为张量，并在TensorBoard中可视化。您将通过一个简单但真实的示例，该示例使用  Image Summaries 来帮助您了解模型的表现。\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22818c6a-ddfb-4a25-91a5-a68519e60d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "  # %tensorflow_version only exists in Colab.\n",
    "    %tensorflow_version 2.x\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# Load the TensorBoard notebook extension.\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9c94c18-3155-473d-9f14-977cd46245db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version:  2.6.0\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import io\n",
    "import itertools\n",
    "from packaging import version\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "\n",
    "print(\"TensorFlow version: \", tf.__version__)\n",
    "assert version.parse(tf.__version__).release[0] >= 2, \\\n",
    "    \"This notebook requires TensorFlow 2.0 or above.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dcc34fb-e9dd-4857-af20-90b8cf54cf8b",
   "metadata": {},
   "source": [
    "## Download the Fashion-MNIST dataset\n",
    "\n",
    "您将构建一个简单的神经网络，在 Fashion-MNIST 数据集中对图像进行分类。该数据集包括来自10个类别的70,000张28x28时尚产品灰度图像，每个类别7,000张图像。\n",
    "\n",
    "首先下载数据："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6c4688-7f1e-47dc-9f38-47b51209eb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the data. The data is already divided into train and test.\n",
    "# The labels are integers representing classes.\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = \\\n",
    "    fashion_mnist.load_data()\n",
    "\n",
    "# Names of the integer classes, i.e., 0 -> T-short/top, 1 -> Trouser, etc.\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', \n",
    "    'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c444f8-a99f-486a-8fd1-d304191e15fa",
   "metadata": {},
   "source": [
    "## Visualizing a single image\n",
    "\n",
    "要了解  Image Summary  API 的工作原理，您现在只需在 TensorBoard 中记录训练集中的第一个训练图像。\n",
    "\n",
    "在此之前，请检查训练数据的形状："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b1b69b8-f6f6-4c0f-94d7-dc847cf06b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  (28, 28)\n",
      "Label:  9 -> Ankle boot\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape: \", train_images[0].shape)\n",
    "print(\"Label: \", train_labels[0], \"->\", class_names[train_labels[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987ce80d-6153-49e0-ab24-a849e33920ee",
   "metadata": {},
   "source": [
    "请注意，数据集中每张图像是形状为(28，28)的 rank-2 张量，代表高度和宽度。\n",
    "\n",
    "然而，`tf.summary.image()` 期望一个包含 `(batch_size、height、width、channels)` 的 rank-4 张量。因此，张量需要被 reshape。\n",
    "\n",
    "您只记录了一张图像，因此 `batch_size` 为 1。图像是灰度的，所以将通道设置为1。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0100ef13-41be-4e6d-85c7-4e070a02f7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the image for the Summary API.\n",
    "img = np.reshape(train_images[0], (-1, 28, 28, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dadc625c-10e0-4bc2-9bfe-74dcd2b4aa54",
   "metadata": {},
   "source": [
    "您现在可以记录此图像并在 TensorBoard 中查看。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed108bab-2d24-4df5-a588-f33777865ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-04 17:33:18.506556: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-04-04 17:33:18.507551: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "# Clear out any prior log data.\n",
    "!rm -rf logs\n",
    "\n",
    "# Sets up a timestamped log directory.\n",
    "logdir = \"logs/train_data/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "# Creates a file writer for the log directory.\n",
    "file_writer = tf.summary.create_file_writer(logdir)\n",
    "\n",
    "# Using the file writer, log the reshaped image.\n",
    "with file_writer.as_default():\n",
    "    tf.summary.image(\"Training data\", img, step=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa4878d-1fb1-40f9-93f1-e9cac09321c5",
   "metadata": {},
   "source": [
    "现在，使用 TensorBoard 检查图像。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca4c8e19-9104-4449-aebb-91a9ca90939a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-35870b185299549e\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-35870b185299549e\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afabf113-1055-47d4-9247-e4f37e8ccaa2",
   "metadata": {},
   "source": [
    "“Images” 选项卡显示您刚刚记录的图像。这是一只 “ankle boot”。\n",
    "\n",
    "图像缩放为默认大小，以便于查看。如果您想查看未缩放的原始图像，请检查左上角的 “Show actual image size”。\n",
    "\n",
    "拖动亮度和对比度滑块，看看它们如何影响图像像素。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424997c6-add4-468f-b50a-817101632631",
   "metadata": {},
   "source": [
    "## Visualizing multiple images\n",
    "\n",
    "记录一个张量很棒，但是如果您想记录多个训练样本呢？\n",
    "\n",
    "只需指定在将数据传递给 `tf.summary.image()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91973b09-838a-47db-8a92-66e2df901604",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 14415), started 0:03:20 ago. (Use '!kill 14415' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-fb5852d598aad920\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-fb5852d598aad920\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with file_writer.as_default():\n",
    "    # Don't forget to reshape.\n",
    "    images = np.reshape(train_images[0:25], (-1, 28, 28, 1))\n",
    "    tf.summary.image(\"25 training data examples\", images, max_outputs=25, step=0)\n",
    "\n",
    "%tensorboard --logdir logs/train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2942a80-726d-45cf-b5d9-ec3e7075b117",
   "metadata": {},
   "source": [
    "## Logging arbitrary image data\n",
    "\n",
    "如果您想可视化非张量的图像，例如由 matplotlib 生成的图像，该怎么办？\n",
    "\n",
    "你需要一些样板代码来将 plot 转换为张量，但之后，你可以走了。\n",
    "\n",
    "在下面的代码中，您将使用 matplotlib 的 `subplot()` 函数将前25张图像记录为一个不错的网格。然后，您将在 TensorBoard 中查看网格："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b51e3c82-b769-4a0a-8d89-e1a09e6b83f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-6bfe0b63a5461b68\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-6bfe0b63a5461b68\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Clear out prior logging data.\n",
    "!rm -rf logs/plots\n",
    "\n",
    "logdir = \"logs/plots/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "file_writer = tf.summary.create_file_writer(logdir)\n",
    "\n",
    "def plot_to_image(figure):\n",
    "    \"\"\"Converts the matplotlib plot specified by 'figure' to a PNG image and\n",
    "    returns it. The supplied figure is closed and inaccessible after this call.\"\"\"\n",
    "    # Save the plot to a PNG in memory.\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='png')\n",
    "    # Closing the figure prevents it from being displayed directly inside\n",
    "    # the notebook.\n",
    "    plt.close(figure)\n",
    "    buf.seek(0)\n",
    "    # Convert PNG buffer to TF image\n",
    "    image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "    # Add the batch dimension\n",
    "    image = tf.expand_dims(image, 0)\n",
    "    return image\n",
    "\n",
    "def image_grid():\n",
    "    \"\"\"Return a 5x5 grid of the MNIST images as a matplotlib figure.\"\"\"\n",
    "    # Create a figure to contain the plot.\n",
    "    figure = plt.figure(figsize=(10,10))\n",
    "    for i in range(25):\n",
    "        # Start next subplot.\n",
    "        plt.subplot(5, 5, i + 1, title=class_names[train_labels[i]])\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        plt.imshow(train_images[i], cmap=plt.cm.binary)\n",
    "    return figure\n",
    "\n",
    "# Prepare the plot\n",
    "figure = image_grid()\n",
    "# Convert to image and log\n",
    "with file_writer.as_default():\n",
    "    tf.summary.image(\"Training data\", plot_to_image(figure), step=0)\n",
    "\n",
    "%tensorboard --logdir logs/plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e51b125-772b-4379-9753-833cacfa8ab2",
   "metadata": {},
   "source": [
    "## Building an image classifier\n",
    "\n",
    "现在把这一切与一个真实的例子放在一起。毕竟，你来这里是为了做机器学习，而不是绘制漂亮的图片！\n",
    "\n",
    "您将使用 image summaries 来了解您的模型在为Fashion-MNIST数据集训练一个简单的分类器时的表现。\n",
    "\n",
    "首先，创建一个非常简单的模型并编译它，设置优化器和损失函数。编译步骤还指定您希望在此过程中记录分类器的准确性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15be283d-18eb-4f3d-b1a2-bd0caf0db262",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam', \n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2280e2f1-db53-4c39-9813-50a3c991c8f2",
   "metadata": {},
   "source": [
    "在训练分类器时，查看混淆矩阵很有用。混淆矩阵让您详细了解分类器在测试数据上的表现。\n",
    "\n",
    "定义一个计算混淆矩阵的函数。您将使用方便的 Scikit-learn 函数来执行此操作，然后使用 matplotlib 绘制。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c765e68b-c1fa-4901-b3cf-0537bcec1e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, class_names):\n",
    "    \"\"\"\n",
    "    Returns a matplotlib figure containing the plotted confusion matrix.\n",
    "\n",
    "    Args:\n",
    "    cm (array, shape = [n, n]): a confusion matrix of integer classes\n",
    "    class_names (array, shape = [n]): String names of the integer classes\n",
    "    \"\"\"\n",
    "    figure = plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title(\"Confusion matrix\")\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(class_names))\n",
    "    plt.xticks(tick_marks, class_names, rotation=45)\n",
    "    plt.yticks(tick_marks, class_names)\n",
    "\n",
    "    # Compute the labels from the normalized confusion matrix.\n",
    "    labels = np.around(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], decimals=2)\n",
    "\n",
    "    # Use white text if squares are dark; otherwise black.\n",
    "    threshold = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        color = \"white\" if cm[i, j] > threshold else \"black\"\n",
    "        plt.text(j, i, labels[i, j], horizontalalignment=\"center\", color=color)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    return figure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ecb16d-bcf6-463d-b621-c3becdd6eb13",
   "metadata": {},
   "source": [
    "您现在可以训练分类器，并在此过程中定期记录混淆矩阵。\n",
    "\n",
    "您将完成以下操作：\n",
    "\n",
    "- 创建 Keras TensorBoard 回调以记录基本指标\n",
    "- 创建一个Keras LambdaCallback，在每个 epoch 结束时记录混淆矩阵\n",
    "- 使用 `Model.fit()` 训练模型，确保传入两个回调\n",
    "\n",
    "随着训练的进行，向下滚动以查看 TensorBoard 启动。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f03f550-a232-4867-96ed-d5273a9d88d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-04 17:53:16.661763: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.\n",
      "2022-04-04 17:53:16.661787: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.\n",
      "2022-04-04 17:53:16.662977: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.\n"
     ]
    }
   ],
   "source": [
    "# Clear out prior logging data.\n",
    "!rm -rf logs/image\n",
    "\n",
    "logdir = \"logs/image/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "# Define the basic TensorBoard callback.\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "file_writer_cm = tf.summary.create_file_writer(logdir + '/cm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e5348f0f-7ff4-415f-a653-5d13afc92205",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_confusion_matrix(epoch, logs):\n",
    "    # Use the model to predict the values from the validation dataset.\n",
    "    test_pred_raw = model.predict(test_images)\n",
    "    test_pred = np.argmax(test_pred_raw, axis=1)\n",
    "\n",
    "    # Calculate the confusion matrix.\n",
    "    cm = sklearn.metrics.confusion_matrix(test_labels, test_pred)\n",
    "    # Log the confusion matrix as an image summary.\n",
    "    figure = plot_confusion_matrix(cm, class_names=class_names)\n",
    "    cm_image = plot_to_image(figure)\n",
    "\n",
    "    # Log the confusion matrix as an image summary.\n",
    "    with file_writer_cm.as_default():\n",
    "        tf.summary.image(\"Confusion Matrix\", cm_image, step=epoch)\n",
    "\n",
    "# Define the per-epoch callback.\n",
    "cm_callback = keras.callbacks.LambdaCallback(on_epoch_end=log_confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b5d35864-1b90-437a-9b78-631c983e6d32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-3cacae53dbe58756\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-3cacae53dbe58756\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6008;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-04 18:01:22.431442: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2022-04-04 18:01:22.434788: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-04-04 18:01:22.591048: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-04 18:01:22.736190: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.\n",
      "2022-04-04 18:01:22.736201: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.\n",
      "2022-04-04 18:01:22.741304: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
      "2022-04-04 18:01:22.744011: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.\n",
      "2022-04-04 18:01:22.747753: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: logs/image/20220404-175316/train/plugins/profile/2022_04_04_18_01_22\n",
      "\n",
      "2022-04-04 18:01:22.748375: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to logs/image/20220404-175316/train/plugins/profile/2022_04_04_18_01_22/Shawns.local.trace.json.gz\n",
      "2022-04-04 18:01:22.750680: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: logs/image/20220404-175316/train/plugins/profile/2022_04_04_18_01_22\n",
      "\n",
      "2022-04-04 18:01:22.750786: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to logs/image/20220404-175316/train/plugins/profile/2022_04_04_18_01_22/Shawns.local.memory_profile.json.gz\n",
      "2022-04-04 18:01:22.751224: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: logs/image/20220404-175316/train/plugins/profile/2022_04_04_18_01_22\n",
      "Dumped tool data for xplane.pb to logs/image/20220404-175316/train/plugins/profile/2022_04_04_18_01_22/Shawns.local.xplane.pb\n",
      "Dumped tool data for overview_page.pb to logs/image/20220404-175316/train/plugins/profile/2022_04_04_18_01_22/Shawns.local.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to logs/image/20220404-175316/train/plugins/profile/2022_04_04_18_01_22/Shawns.local.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to logs/image/20220404-175316/train/plugins/profile/2022_04_04_18_01_22/Shawns.local.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to logs/image/20220404-175316/train/plugins/profile/2022_04_04_18_01_22/Shawns.local.kernel_stats.pb\n",
      "\n",
      "2022-04-04 18:01:28.631939: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-04 18:01:29.385406: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11f8b9d00>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start TensorBoard.\n",
    "%tensorboard --logdir logs/image\n",
    "\n",
    "# Train the classifier.\n",
    "model.fit(\n",
    "    train_images,\n",
    "    train_labels,\n",
    "    epochs=5,\n",
    "    verbose=0, # Suppress chatty output\n",
    "    callbacks=[tensorboard_callback, cm_callback],\n",
    "    validation_data=(test_images, test_labels),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad3f82f-0623-4e64-a097-c8ecf03d7e8c",
   "metadata": {},
   "source": [
    "请注意，训练和验证集的准确性都在攀升。这是个好兆头。但是，该模型在数据的特定子集上的表现如何？\n",
    "\n",
    "选择 “Image” 选项卡以可视化您记录的混淆矩阵。检查左上角的“Show actual image size”，以查看完整大小的混淆矩阵。\n",
    "\n",
    "默认情况下，dashboard 显示最后一个记录步骤或 epoch 的 image summary。使用 slider 查看早期的混淆矩阵。注意矩阵如何随着训练的进展而发生重大变化，较暗的正方形沿着对角线合并，而矩阵的其余部分趋向0和白色。这意味着随着训练的进展，您的分类器正在改进！干得好！\n",
    "\n",
    "混淆矩阵表明，这个简单的模型存在一些问题。尽管取得了巨大进步，但衬衫、T恤和套头衫正在相互混淆。该模型需要更多的工作。\n",
    "\n",
    "如果您有兴趣，请尝试使用卷积网络（CNN）改进此模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0353ee-1b52-4da5-a05a-1b4128b401f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
